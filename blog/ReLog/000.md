---
title: Win10 & AMD5700XT 试图使用comfyUI的尝试
tags: ['comfyUI']
desc: "从方案一到方案三，掌握了很多有的没的的内容。总之本地运行不可能，还是上云端。"
---

# 背景

需要验证一下A卡炼丹，然后发现真是小众的需求呢，非常的有得折腾，因此写了这篇笔记。算了一下，一共耗时5-6个小时。

## 已经知道的情报

[A卡炼丹的最优选择（可能也是唯一选择）：ComfyUI](https://zhuanlan.zhihu.com/p/672675578)

## 设备情况

AMD RT 5700XT

Windows 10

# 方案一 适用于AMD6600以上

记录一下过程

## 参考教程

1. [AMD如何使用ComfyUI](https://www.bilibili.com/video/BV1bm411R7st), 这个作者的显卡是6600XT 
2. [AMD GPU + Windows + ComfyUI! How to get comfyUI running on windows with an AMD GPU!](https://www.youtube.com/watch?v=8rB7RqKvU5U) 这个作者是上面作者参考的作者。

## 安装anaconda

下载地址：[anaconda](https://www.anaconda.com/download)

最后的时候最后记得勾选 add to PATH. 

## 运行anaconda

菜单栏 anaconda prompt ，等于是配套的命令行工具。

## 创建环境

```bash
conda create --name comfyui python=3.10.12
```

> 使用 Conda 工具创建了一个名为 "comfyui" 的虚拟环境，并指定了 Python 版本为 3.10.12。

这个环境对应在本地的`d:\libregd\anaconda\envs\comfyui` ，文件夹生成在哪里，取决于安装anaconda的时候你选了安装在哪个盘哪个文件夹，默认是C盘。

## 激活虚拟环境

```bash
conda activate comfyui 
```

> - `conda activate`: 这是 Conda 包管理工具的一个命令，用于激活虚拟环境。
> - `comfyui`: 这是你想要激活的虚拟环境的名称，在这个例子中就是 "comfyui"。
>
> 执行这个命令后，你的命令行提示符将会更改，显示当前已激活的环境名称，这意味着你正在使用指定的虚拟环境。这样，你就可以在这个环境中安全地运行 Python 脚本或者安装其他依赖，而不会影响到系统中的其他环境。
>
> 这使得用户可以在不同的环境中工作，每个环境可以有自己独立的软件包集合和配置。

## 拉取comfyUI并进入

```bash
git clone https://github.com/comfyanonymous/ComfyUI.git
cd comfyui
```

进入环境以后，主要是先下载comfyUI，然后进入对应的目录。

## 安装torch和别的配置

```bash
pip install torch-directml
```

> https://pypi.org/project/torch-directml/ 
>
> 这个是torch的特别版本，可以说是为了AMD专门搞出来的。
>
> Successfully installed MarkupSafe-2.1.5 filelock-3.14.0 fsspec-2024.5.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 pillow-10.3.0 sympy-1.12 torch-2.2.1 torch-directml-0.2.1.dev240521 torchvision-0.17.1 typing-extensions-4.12.0

可以看得出来安装的东西比较多。 torch-2.2.1

```bash
pip install -r requirements.txt
```

> Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 colorama-0.4.6 einops-0.8.0 frozenlist-1.4.1 huggingface-hub-0.23.1 idna-3.7 kornia-0.7.2 kornia-rs-0.1.3 multidict-6.0.5 packaging-24.0 psutil-5.9.8 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.2 safetensors-0.4.3 scipy-1.13.1 tokenizers-0.19.1 torchsde-0.2.6 tqdm-4.66.4 trampoline-0.1.2 transformers-4.41.1 urllib3-2.2.1 yarl-1.9.4

这条也有好多安装的。

## 启动comfy

```bash
python main.py --directml
```

> Using directml with device:
> Total VRAM 1024 MB, total RAM 32701 MB
> pytorch version: 2.2.1+cpu
> Set vram state to: NORMAL_VRAM
> Device: privateuseone
> VAE dtype: torch.float32
> Using sub quadratic optimization for cross attention, if you have memory or speed issues try using: --use-split-cross-attention
> ****** User settings have been changed to be stored on the server instead of browser storage. ******
> ****** For multi-user setups add the --multi-user CLI argument to enable multiple user profiles. ******
>
> Import times for custom nodes:
>    0.0 seconds: C:\Users\libregd\ComfyUI\custom_nodes\websocket_image_save.py
>
> Starting server
>
> To see the GUI go to: http://127.0.0.1:8188

`pytorch version: 2.2.1+cpu` 这句话说明还是用的cpu啊

这样启动成功的comfyUI有啥意义？自闭了，关掉命令行。

不过如果正常，没有这句话，也就是AMD显卡信号6600+可以考虑继续跟着方案一的参考教程做完后续。

## 验证猜想

###  DirectML是啥？

> chatGPT: 
>
> 使用 DirectML 支持的 PyTorch 版本来利用 AMD GPU 时，对 GPU 型号有一些要求，但你的 AMD RX 5700 XT 是支持的。DirectML 是一个跨平台的机器学习加速库，旨在为 Windows 10 上的各种 GPU 提供支持，包括 AMD 和 NVIDIA 的显卡。
>
> DirectML 可以在支持 DirectX 12 的 GPU 上运行。AMD RX 5700 XT 支持 DirectX 12，因此可以使用 DirectML。

在`pip install torch-directml`以后,就已经安装了特定的torch，就可以用下面的代码验证你的 AMD GPU 是否可以使用 DirectML：

```python
# testTorchVer.py
import torch

# 检查 DirectML 设备是否可用

if torch.cuda.is_available():
    device = torch.device('dml')
    print("DirectML device is available.")
else:
    device = torch.device('cpu')
    print("Using CPU as fallback.")

# 创建张量并移动到 DirectML 设备

tensor = torch.tensor([1.0, 2.0, 3.0]).to(device)

# 打印张量信息

print(tensor)
print(f"Tensor device: {tensor.device}")
```

### 怎么放到对应的虚拟环境下？

毕竟实在虚拟环境下进行的以上各种安装配置，因此我感觉测试也得放到这个环境中。

```bash
(base) C:\Users\libregd>cd ComfyUI
(base) C:\Users\libregd\ComfyUI> conda activate comfyui
```

上面这两个命令，通过菜单栏的anaconda prompt进入对应的文件夹（不确认是否必须），并激活虚拟空间，然后就会变成这样：

```bash
(comfyui) C:\Users\libregd \ComfyUI>
```

#### 查看torch版本

```bash
pip show torch
```

> Name: torch
> Version: 2.2.1
> Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration
> Home-page: https://pytorch.org/
> Author: PyTorch Team
> Author-email: packages@pytorch.org
> License: BSD-3
> Location: d:\libregd\anaconda\envs\comfyui\lib\site-packages
> Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions
> Required-by: torch-directml, torchvision

看得出来torch版本是非常新的。

#### echo不好用

尝试了echo ，`python test.py`可以运行，但是毕竟这个文件还是文本比较多，不太适合。

```bash
(comfyui) C:\Users\libregd\ComfyUI>echo print("hello!!!!!!") > test.py
```

#### navigator也不支持

 Anaconda Navigator 是anaconda配套的GUI,可以管理不少事：

chatGPT：

> 在 Anaconda Prompt 中创建的环境可以在 Anaconda Navigator 中访问。Anaconda Navigator 是一个用于管理 Conda 环境和软件包的图形用户界面（GUI）工具，它可以显示并管理所有通过 Conda 创建的环境，无论是通过命令行还是通过 Navigator 自身。
>
> 当你在 Anaconda Prompt 中创建一个新的环境后，它会自动显示在 Anaconda Navigator 的环境列表中。你可以在 Navigator 中切换到这个新创建的环境，并在其中安装、更新或删除软件包，就像在命令行中一样。这使得在 GUI 和命令行之间切换变得更加方便，以满足用户不同的需求。
>
> 1. 在 Navigator 中的 "Home" 标签下，点击 "Environments"。
> 2. 在 "Environments" 页面中，选择你想要安装 Notepad++ 的环境（比如 base 或者你自己创建的环境）。
> 3. 在环境列表中，选择 "Not installed"，然后在搜索框中输入 "notepad++"。
> 4. 在搜索结果中找到 Notepad++，勾选它，并点击 "Apply" 按钮来安装。
> 5. 安装完成后，你就可以在 Anaconda Prompt 中使用 Notepad++ 了。

实际并不行，里面压根没有notepad++，也没有vim/vi ，也没有vscode，天。

#### jupyter notebook 正解

anaconda是一组套件，还有个jupyter notebook，总之在程序启动栏点开就打开了一个web浏览器：

```bash
http://localhost:8888/tree
```
我：是否可以通过访问jupyter notebook访问anaconda的虚拟环境下的各种文本文档，比如`.txt` `.py` `.js` ？以及新建各种文本文档。

chatGPT:

> Jupyter Notebook 可以访问 Anaconda 虚拟环境下的各种文本文档，包括 .txt、.py、.js 等文件。当你在 Jupyter Notebook 中打开一个 notebook 文件时，你可以通过文件系统浏览器或者 Jupyter Notebook 提供的命令来访问并操作虚拟环境下的其他文件。
>
> 具体来说，你可以在 Jupyter Notebook 中使用以下方式来访问虚拟环境下的文件：
>
> 1. **通过文件系统浏览器：** Jupyter Notebook 提供了一个文件系统浏览器界面，你可以通过界面上的文件夹图标来浏览虚拟环境下的文件和文件夹。你可以单击文件夹图标进入文件夹，查看其中的文件；也可以单击文件图标打开文件进行编辑。
> 2. **通过命令行：** 在 Jupyter Notebook 的代码单元格中，你可以使用系统命令来访问虚拟环境下的文件。比如，你可以使用 Python 的内置 `open()` 函数来读取和写入 .txt 和 .py 文件；或者使用其他命令来执行一些操作，比如在虚拟环境中创建新的文件。
> 3. **通过 Jupyter Notebook 的扩展功能：** Jupyter Notebook 还支持各种扩展功能和插件，你可以安装一些扩展来增强 Jupyter Notebook 的文件操作能力。比如，安装 JupyterLab 可以提供更强大的文件管理和编辑功能，包括新建文件、复制粘贴等操作。
>
> 总之，通过 Jupyter Notebook 可以方便地访问和操作 Anaconda 虚拟环境下的各种文本文档，并且可以通过安装扩展来增强文件操作的功能。

总之通过在`http://localhost:8888/tree/ComfyUI` 这个浏览器页面中，实现了新建文件，编写文件`testTorchVer.py`。

#### 本地文件夹 正解

```bash
C:\Users\libregd\ComfyUI
```

在这个地方我找到了新建的`testTorchVer.py`，也就是说，anaconda确实虚拟了一个环境。只在自己的生态内（anaconda prompt，anaconda navigator，Jupiter notebook）映射你创建的内容。

### 验证结果

总算可以验证了,

```bash
(comfyui) C:\Users\libregd \ComfyUI>python testTorchVer.py
```

> Using CPU as fallback.
> tensor([1., 2., 3.])
> Tensor device: cpu

也就是说，特定的`torch-directml`并没有真的支持AMD 5700，至少comfyUI隐晦的暗示了AMD的显卡型号底线。

> https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#running 
>
> > For 6700, 6600 and maybe other RDNA2 or older: `HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py`
> >
> > For AMD 7600 and maybe other RDNA3 cards: `HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py`
>
> 感觉5700版本太低了哈哈哈。

## 删除虚拟环境

```bash
conda remove --name comfyui --all
```

这个不是我很想要的效果，所以我删除了这个虚拟环境。`d:\libregd\anaconda\envs\comfyui` 确实随着这条命令消失了。

然而`C:\Users\libregd\ComfyUI` 这个拉取的github仓库还存在。



# 方案二 windows下webUI天选分支

A卡买的时候，价格真香了。5700 XT 可以双系统 win + mac 赚到了。炼丹的时候，低端A卡落泪了 （A卡生态不挤牙膏，我推测导致核心在版本号之间变动特别大，directML估计感觉钱少事多收益不行，就没兼顾太多A卡。）

AMD 5700XT 即便是在Linux下都需要很多额外的设置，比如

```bash
pip install torch==1.13.1+rocm5.2 torchvision==0.14.1+rocm5.2 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/rocm5.2
```

rocm 专供linux用，虚拟机/wsl 可能都不好使，双系统/云主机应该可行（也就是要操作系统就是linux)，但是我没有计划把win换成linux，双系统也不是个策略，因为日常软件生态暂时在win。

## 参考资料

1. [How to ComfyUI on AMD Radeon RX 5700 XT](https://github.com/comfyanonymous/ComfyUI/discussions/1119) ：这篇提供了一个相对详细的安装过程命令详解, but linux
2. [HIP error: invalid device function when running ComfyUI](https://github.com/comfyanonymous/ComfyUI/issues/2842) : 这篇很多关于directML的缺陷讨论。

## 结论

假设不搞comfyUI，退一步海阔天空，找stable-diffusion-webui：[Install-and-Run-on-AMD-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs), 就会发现，

这个分支维护者自己好像就是5700 :[I can't reproduce it with my RX 5700 XT](https://github.com/lshqqytiger/stable-diffusion-webui-amdgpu/issues/112) , 不过看修bug ，完全是自己的需求，结果issue里充满了各种他没办法干涉的疑难杂症，看着就心累。

但是我已经不想玩webUI了，即便我没怎么玩，我想玩节点的comfyUI.

# 方案三 云端部署comfyUI

有些钱还是要花的

1. [Your Options for Running ComfyUI in the Cloud](https://medium.com/code-canvas/your-options-for-running-comfyui-in-the-cloud-162b77decebe) :分析了怎么在云上搞得几种策略和推荐了一些产品，等于导读。

2. [云端安装 ComfyUI](https://www.comflowy.com/zh-CN/preparation-for-study/install-cloud)：给出了非常详细的教程，和省钱指南，方案三的主要参考教程。

## 步骤要点

1. 推荐了kaggle，主要是每个星期可以白嫖GPU（T4 × 2） 30个小时，以代码启动后的时间点开始算。也就是说暂停服务就可以完全够用了，不用像国内一样，管你用不用都在计费。
2. kaggle需要手机验证，老中号码可行。我感觉换个邮箱+接码平台可以无限白嫖。（但30h对我来说一周完全足够了）

# 本文总结

折腾半天还是上云了，现在的要点是学习comfyUI，这个界面乍看很眼熟，毕竟blender里也有几何节点.

以及我第一次用comfyUI，就是仅仅使用cpu性能在blender里使用的插件：[ComfyUI-BlenderAI-node](https://github.com/AIGODLIKE/ComfyUI-BlenderAI-node)

后续的安排是总结学习comfyUI的经验，这篇文章起因是想验证一个画画前期的测试想法，现在感觉像个踩坑吐槽文。

